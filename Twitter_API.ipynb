{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter_API.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "clrzxf-N9hnF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tweepy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXyWKPqT9mxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tweepy\n",
        "import pandas as pd\n",
        "\n",
        "#Add your credentials here\n",
        "twitter_keys = {\n",
        "        'consumer_key':        'XXX',\n",
        "        'consumer_secret':     'XXX',\n",
        "        'access_token_key':    'XXX',\n",
        "        'access_token_secret': 'XXX'\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIbNCnu69qqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Setup access to API\n",
        "auth = tweepy.OAuthHandler(twitter_keys['consumer_key'], twitter_keys['consumer_secret'])\n",
        "auth.set_access_token(twitter_keys['access_token_key'], twitter_keys['access_token_secret'])\n",
        "\n",
        "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56KStRdX9u0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets = []\n",
        "count = 1\n",
        "from dateutil.parser import parse\n",
        "from datetime import datetime, timedelta\n",
        "from pytz import timezone\n",
        " \n",
        "gmt = timezone('Asia/Kolkata')\n",
        "last_hour_date_time = datetime.now(gmt) - timedelta(hours = 150)\n",
        "print(last_hour_date_time)\n",
        "\n",
        "users = []\n",
        "page_count = 0\n",
        "\n",
        "for tweet in tweepy.Cursor(api.search, q=\"#covid OR #covid19 OR #covid-19 OR #corona OR #StayHome OR #StaySafe OR #coronavirus -filter:retweets\", \n",
        "                           count=5000,  since=last_hour_date_time.strftime('%Y-%m-%d %H'), tweet_mode='extended', lang=\"en\").items(1000):\n",
        "\n",
        "#for tweet in tweepy.Cursor(api.search, q=\"#covid OR #covid19 OR #covid-19 OR #corona OR #StayHome OR #StaySafe OR #coronavirus -filter:retweets\", \n",
        "#                           count=5000, since='2020-04-06', tweet_mode='extended', lang=\"en\").items(1000):\n",
        "    data = [tweet.created_at, tweet.full_text, tweet.user._json['name'], tweet.user._json['screen_name'], tweet.user._json['id'], tweet.user._json['location'], \n",
        "            tweet.user._json['followers_count'], parse(tweet.user._json['created_at']).strftime(\"%d-%m-%Y\"), tweet.user._json['statuses_count'], tweet.user._json['friends_count'],\n",
        "            tweet.user._json['listed_count'], tweet.user._json['favourites_count']]\n",
        "\n",
        "    data = tuple(data)\n",
        "    tweets.append(data)\n",
        "    continue\n",
        "\t\n",
        "df = pd.DataFrame(tweets, columns = ['tweet_time', 'tweet_text', 'username', 'user_screenname', 'userid', 'location', 'followers_count',\n",
        "                                     'twtr_joined_on', 'statuses_count', 'friends_count', 'listed_count', 'favourites_count'])\n",
        "\n",
        "print(\"df ready : \", df.shape )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y0iJ-zrE766",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preprocessing\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "!pip install tweet-preprocessor\n",
        "import preprocessor as p\n",
        "p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.SMILEY, p.OPT.EMOJI)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmDdTOdQIZNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "cleantweetsNOPunct = []\n",
        "import string\n",
        "table = str.maketrans('','', string.punctuation)\n",
        "\n",
        "for tweet in df['tweet_text']:\n",
        "    try:\n",
        "        tweet = p.clean(tweet)\n",
        "        #tokenize\n",
        "        words2 = word_tokenize(tweet.lower())\n",
        "        #remove puncts\n",
        "        words3 = [w.translate(table) for w in words2]\n",
        "        cleantweetsNOPunct.append((\" \".join(words3)).strip())\n",
        "    except:\n",
        "        cleantweetsNOPunct.append(tweet)\n",
        "        continue\n",
        "\n",
        "print(len(cleantweetsNOPunct))\n",
        "\n",
        "df['clean_Tweet_NoPunct'] = cleantweetsNOPunct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kiD4aNFIRXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#filename = \"Covid19_Tweets\" + str(datetime.now(gmt).strftime('%Y-%m-%d %H:%M')) + \".csv\"\n",
        "filename = \"Covid19_Tweets\" + str(last_hour_date_time).replace(\" \", \"\") + \".csv\"\n",
        "\n",
        "df.to_csv(filename, index=False)\n",
        "print(filename + \" stored as csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
