{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "twitterapi.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOS38BawG3Jd79fhFl2VGvB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CTiWrYpYfC_",
        "colab_type": "code",
        "outputId": "c69de012-9e21-44b9-8fe9-bbb44ae9885e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!pip install tweepy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.12.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.3.0)\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.7.1)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy) (2.21.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (2019.11.28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kniijvjqqxXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tweepy\n",
        "import pandas as pd\n",
        "\n",
        "#Add your credentials here\n",
        "twitter_keys = {\n",
        "        'consumer_key':        'AEbc4H567rAHtz2ARzZt4geIc',\n",
        "        'consumer_secret':     'hlYDO5yQiBH1wPrOnQUFCmUQ63Zc7g4IjkziwbuO4ylweWF7ju',\n",
        "        'access_token_key':    '96138566-KKPVdu8iY8QJU4D0w9PDXxHlqaSMYUxqAhvWAUVdJ',\n",
        "        'access_token_secret': 'cMVOYLeq9IG8geovmi8ZZxLl2QEH80FDwRXvrfe91nWb5'\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgnKn5zArY5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Setup access to API\n",
        "auth = tweepy.OAuthHandler(twitter_keys['consumer_key'], twitter_keys['consumer_secret'])\n",
        "auth.set_access_token(twitter_keys['access_token_key'], twitter_keys['access_token_secret'])\n",
        "\n",
        "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECjc0dW6tx4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets = []\n",
        "count = 1\n",
        "from dateutil.parser import parse\n",
        "from datetime import datetime\n",
        "users = []\n",
        "page_count = 0\n",
        "\n",
        "for tweet in tweepy.Cursor(api.search, q=\"#covid OR #covid19 OR #covid-19 OR #corona OR #StayHome OR #StaySafe OR #coronavirus -filter:retweets\", \n",
        "                           count=5000,  since='2020-04-08', tweet_mode='extended', lang=\"en\").items(100000):\n",
        "    count = count + 1\n",
        "    print(count)\n",
        "    data = [tweet.created_at, tweet.full_text, tweet.user._json['name'], tweet.user._json['screen_name'], tweet.user._json['id'], tweet.user._json['location'], \n",
        "            tweet.user._json['followers_count'], parse(tweet.user._json['created_at']).strftime(\"%d-%m-%Y\"), tweet.user._json['statuses_count'], tweet.user._json['friends_count'],\n",
        "            tweet.user._json['listed_count'], tweet.user._json['favourites_count']]\n",
        "    data = tuple(data)\n",
        "    tweets.append(data)\n",
        "   \n",
        "    #except tweepy.TweepError as e:\n",
        "\t#print(e.reason)\n",
        "    continue\n",
        "\t#except StopIteration:\n",
        "\t#    break\n",
        "\n",
        "df = pd.DataFrame(tweets, columns = ['tweet_time', 'tweet_text', 'username', 'user_screenname', 'userid', 'location', 'followers_count',\n",
        "                                     'twtr_joined_on', 'statuses_count', 'friends_count', 'listed_count', 'favourites_count'])\n",
        "\n",
        "df.to_csv(\"Covid19_Tweets_all.csv\", index=False)\n",
        "print(\"Covid19_Tweets_all stored as csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dSwk6v0HSyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "retweets = []\n",
        "count = 1\n",
        "\n",
        "for tweet in tweepy.Cursor(api.search, q=\"#covid OR #covid19 OR #covid-19 OR #corona OR #StayHome OR #StaySafe OR #coronavirus filter:retweets\", \n",
        "                           count=5000,  since='2020-04-08', tweet_mode='extended', lang=\"en\").items(100000):\n",
        "    count = count + 1\n",
        "    print(count)\n",
        "    data = [tweet.created_at, tweet.full_text, tweet.user._json['name'], tweet.user._json['screen_name'], tweet.user._json['id'], tweet.user._json['location'], \n",
        "            tweet.user._json['followers_count'], parse(tweet.user._json['created_at']).strftime(\"%d-%m-%Y\"), tweet.user._json['statuses_count'], tweet.user._json['friends_count'],\n",
        "            tweet.user._json['listed_count'], tweet.user._json['favourites_count']]\n",
        "    data = tuple(data)\n",
        "    retweets.append(data)\n",
        "    #except tweepy.TweepError as e:\n",
        "\t#print(e.reason)\n",
        "    continue\n",
        "\t#except StopIteration:\n",
        "\t#    break\n",
        "\n",
        "df = pd.DataFrame(retweets, columns = ['tweet_time', 'tweet_text', 'username', 'user_screenname', 'userid', 'location', 'followers_count',\n",
        "                                     'twtr_joined_on', 'statuses_count', 'friends_count', 'listed_count', 'favourites_count'])\n",
        "\n",
        "df.to_csv(\"Covid19_Retweets_all.csv\", index=False) \n",
        "\n",
        "print(\"Covid19_Retweets_all stored as csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDtAFRgAsBf6",
        "colab_type": "code",
        "outputId": "8856c0e1-759e-4f93-e1b1-c0d095da2b11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "df = pd.read_csv(\"sample_data/Covid19_Tweets_all.csv\")\n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,1,2,3,4,5,6,7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(360989, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPHgOvi6cCvT",
        "colab_type": "code",
        "outputId": "9a6119c1-616e-422d-ac98-72aeff510049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW4XzTvA0HZS",
        "colab_type": "code",
        "outputId": "e38ab1b7-bcc8-44ef-b988-170fbb56283d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!pip install tweet-preprocessor\n",
        "import preprocessor as p\n",
        "p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.SMILEY, p.OPT.EMOJI)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tweet-preprocessor\n",
            "  Downloading https://files.pythonhosted.org/packages/2a/f8/810ec35c31cca89bc4f1a02c14b042b9ec6c19dd21f7ef1876874ef069a6/tweet-preprocessor-0.5.0.tar.gz\n",
            "Building wheels for collected packages: tweet-preprocessor\n",
            "  Building wheel for tweet-preprocessor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tweet-preprocessor: filename=tweet_preprocessor-0.5.0-cp36-none-any.whl size=7947 sha256=35107bf097a68c26ba2d312b67a0895f7f83a4dd16544239a7db74927e5bce77\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/27/cc/49938e98a2470802ebdefae9d2b3f524768e970c1ebbe2dc4a\n",
            "Successfully built tweet-preprocessor\n",
            "Installing collected packages: tweet-preprocessor\n",
            "Successfully installed tweet-preprocessor-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGQM73IrYg4Y",
        "colab_type": "code",
        "outputId": "f8682291-1fa7-4bb5-a0a0-692f532c34fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "cleantweetsNOPunct = []\n",
        "import string\n",
        "table = str.maketrans('','', string.punctuation)\n",
        "\n",
        "for tweet in df['tweet_text']:\n",
        "    try:\n",
        "        #tweet1 = p.clean(tweet)\n",
        "        #tweet = tweet[tweet.find(':')+1:]\n",
        "        #tokenize\n",
        "        words2 = word_tokenize(tweet.lower())\n",
        "        #remove puncts\n",
        "        words3 = [w.translate(table) for w in words2]\n",
        "        cleantweetsNOPunct.append((\" \".join(words3)).strip())\n",
        "    except:\n",
        "        cleantweetsNOPunct.append(tweet)\n",
        "        continue\n",
        "\n",
        "print(len(cleantweetsNOPunct))\n",
        "\n",
        "df['clean_Tweet_NoPunct'] = cleantweetsNOPunct\n",
        "\n",
        "#df = pd.DataFrame(tweets, columns = ['created_at', 'tweet_text', 'location', 'username', 'userid'])\n",
        "#df.to_csv(\"Covid19_Tweets.csv\", index=False)\n",
        "#print(\"Covid19_Tweets stored as csv\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "360989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q21JuhuuhuQy",
        "colab_type": "code",
        "outputId": "25468d95-b5d2-4dae-ca62-af0c73ea7fe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "data['clean_Tweet_NoPunct']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         lsai clever cryptography could protect privacy...\n",
              "1         if you find yourself suddenly homeschooling  i...\n",
              "2         party till you drop   covidiots  covid19  stay...\n",
              "3         huge  mn senator and dr reveals hhs document c...\n",
              "4         a friendly note for all those cyclists and run...\n",
              "                                ...                        \n",
              "360984    france to extend nationwide lockdown as  coron...\n",
              "360985    smartdissent no wonder trump was nt ready for ...\n",
              "360986    if i see another idiot doing sit ups  squats  ...\n",
              "360987    reuters new zealand has reported approx 1200 c...\n",
              "360988    ♫  nowplaying “ oh dreamer ” by the brilliance...\n",
              "Name: clean_Tweet_NoPunct, Length: 360989, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ztr2G5qYyif",
        "colab_type": "code",
        "outputId": "19c282f4-2f50-42d3-c422-b3308ee69c19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "cleantweetsNOPunctNoStop = []\n",
        "\n",
        "for tweet in data1['clean_Tweet_NoPunct']:\n",
        "    #tokenize\n",
        "    words2 = word_tokenize(tweet.lower())\n",
        "    #stop words\n",
        "    words3 = [w for w in words2 if not w in stop_words]\n",
        "    #words3 = [word for word in stripped if word.isalpha()]\n",
        "    cleantweetsNOPunctNoStop.append((\" \".join(words3)).strip())\n",
        "    \n",
        "data1['clean_Tweet_NoPunctNoStop'] = cleantweetsNOPunctNoStop\n",
        "\n",
        "#df = pd.DataFrame(tweets, columns = ['created_at', 'tweet_text', 'location', 'username', 'userid'])\n",
        "#df.to_csv(\"Covid19_Tweets.csv\", index=False)\n",
        "#print(\"Covid19_Tweets stored as csv\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAqm_zz5iZhF",
        "colab_type": "code",
        "outputId": "063191db-92ad-4038-895c-70c6252c1348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "cleantweetsNOPunctNoStopNoNumber = []\n",
        "\n",
        "for tweet in data1['clean_Tweet_NoPunctNoStop']:\n",
        "    #tokenize\n",
        "    words2 = word_tokenize(tweet.lower())\n",
        "    #stop words\n",
        "    words3 = [w for w in words2 if not w in stop_words]\n",
        "    words4 = [word for word in words3 if word.isalpha()]\n",
        "    cleantweetsNOPunctNoStopNoNumber.append((\" \".join(words4)).strip())\n",
        "    \n",
        "data1['clean_Tweet_NoPunctNoStopNoNumber'] = cleantweetsNOPunctNoStopNoNumber\n",
        "\n",
        "#df = pd.DataFrame(tweets, columns = ['created_at', 'tweet_text', 'location', 'username', 'userid'])\n",
        "#df.to_csv(\"Covid19_Tweets.csv\", index=False)\n",
        "#print(\"Covid19_Tweets stored as csv\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2bCGmWzjLVI",
        "colab_type": "code",
        "outputId": "2035f18c-8273-4ec6-bec7-2ace1861701a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.to_csv(\"Covid19_Tweets_all_9April.csv\", index=False) \n",
        "\n",
        "print(\"Covid19_Tweets_all_9April stored as csv\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Covid19_Tweets_all_9April stored as csv\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}